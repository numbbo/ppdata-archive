\providecommand{\bbobecdfcaptionsinglefunctionssingledim}[1]{
Empirical cumulative distribution of simulated (bootstrapped)
             runtimes, measured in number of objective function evaluations,
             divided by dimension (FEvals/DIM) for the $58$ 
             targets $\{-10^{-4}, -10^{-4.2}, $ $-10^{-4.4}, -10^{-4.6}, -10^{-4.8}, -10^{-5}, 0, 10^{-5}, 10^{-4.9}, 10^{-4.8}, \dots, 10^{-0.1}, 10^0\}$ in dimension #1.
}
\providecommand{\cocoversion}{\hspace{\textwidth}\scriptsize\sffamily{}\color{Gray}Data produced with COCO v2.2.2.644, hv-hashes inconsistent: 9c62f617dadcb154 and ff0e71e8cd978373 found!}
\providecommand{\numofalgs}{7}
\providecommand{\bbobECDFslegend}[1]{
Bootstrapped empirical cumulative distribution of the number of objective function evaluations divided by dimension (FEvals/DIM) for $58$ targets with target precision in $\{-10^{-4}, -10^{-4.2}, $ $-10^{-4.4}, -10^{-4.6}, -10^{-4.8}, -10^{-5}, 0, 10^{-5}, 10^{-4.9}, 10^{-4.8}, \dots, 10^{-0.1}, 10^0\}$ for all functions and subgroups in #1-D. As reference algorithm, the best algorithm from BBOB 2016 is shown as light thick line with diamond markers.
}
\providecommand{\bbobppfigslegend}[1]{
Average running time (\aRT\ in number of $f$-evaluations
                    as $\log_{10}$ value), divided by dimension for target function value $10^{-5}$
                    versus dimension. Slanted grid lines indicate quadratic scaling with the dimension. Different symbols correspond to different algorithms given in the legend of #1. Light symbols give the maximum number of function evaluations from the longest trial divided by dimension. Black stars indicate a statistically better result compared to all other algorithms with $p<0.01$ and Bonferroni correction number of dimensions (six).  
Legend: 
{\color{NavyBlue}$\circ$}: \algorithmA
, {\color{Magenta}$\diamondsuit$}: \algorithmB
, {\color{Orange}$\star$}: \algorithmC
, {\color{CornflowerBlue}$\triangledown$}: \algorithmD
, {\color{red}$\varhexagon$}: \algorithmE
, {\color{YellowGreen}$\triangle$}: \algorithmF
, {\color{cyan}$\pentagon$}: \algorithmG
}
% define some COCO/dvipsnames colors because
% ACM style does not allow to use them directly
\definecolor{NavyBlue}{HTML}{000080}
\definecolor{Magenta}{HTML}{FF00FF}
\definecolor{Orange}{HTML}{FFA500}
\definecolor{CornflowerBlue}{HTML}{6495ED}
\definecolor{YellowGreen}{HTML}{9ACD32}
\definecolor{Gray}{HTML}{BEBEBE}
\definecolor{Yellow}{HTML}{FFFF00}
\definecolor{GreenYellow}{HTML}{ADFF2F}
\definecolor{ForestGreen}{HTML}{228B22}
\definecolor{Lavender}{HTML}{FFC0CB}
\definecolor{SkyBlue}{HTML}{87CEEB}
\definecolor{NavyBlue}{HTML}{000080}
\definecolor{Goldenrod}{HTML}{DDF700}
\definecolor{VioletRed}{HTML}{D02090}
\definecolor{CornflowerBlue}{HTML}{6495ED}
\definecolor{LimeGreen}{HTML}{32CD32}

\providecommand{\ntables}{4}
\providecommand{\ntables}{4}
\providecommand{\ntables}{4}
\providecommand{\pptablesfooter}{
\end{tabularx}
}
\providecommand{\pptablesheader}{
\begin{tabularx}{1.0\textwidth}{@{}c@{}|*{4}{@{}r@{}X@{}}|@{}r@{}@{}l@{}}
$\Df$ & \multicolumn{2}{@{\,}l@{\,}}{1e0} & \multicolumn{2}{@{\,}l@{\,}}{1e-1} & \multicolumn{2}{@{\,}l@{\,}}{1e-2} & \multicolumn{2}{@{\,}l@{\,}}{1e-3} & \multicolumn{2}{|@{}l@{}}{\begin{rotate}{30}\#succ\end{rotate}}\\\hline
}
\providecommand{\algGtables}{\StrLeft{SPEA2}{\ntables}}
\providecommand{\algFtables}{\StrLeft{NSGA-II}{\ntables}}
\providecommand{\algEtables}{\StrLeft{N-III-111}{\ntables}}
\providecommand{\algDtables}{\StrLeft{N-III-11}{\ntables}}
\providecommand{\algCtables}{\StrLeft{MOEAD}{\ntables}}
\providecommand{\algBtables}{\StrLeft{IBEA}{\ntables}}
\providecommand{\algAtables}{\StrLeft{GDE3}{\ntables}}
\providecommand{\ntables}{4}
\providecommand{\ntables}{4}
\providecommand{\ntables}{4}
\providecommand{\bbobpptablesmanylegend}[1]{%
        Average runtime (\aRT\ in number of function 
        evaluations) divided by the respective best \aRT\ measured during BBOB-2016 in
        #1.
        This \aRT\ ratio and, in braces as dispersion measure, the half difference between
        10 and 90\%-tile of bootstrapped run lengths appear for each algorithm and 
        %
        target, the corresponding reference \aRT\
        in the first row. The different target \DI-values are shown in the top row.
        \#succ is the number of trials that reached the (final) target
        $\hvref + 10^{-5}$.
        %
        The median number of conducted function evaluations is additionally given in 
        \textit{italics}, if the target in the last column was never reached.
        Entries, succeeded by a star, are statistically significantly better (according to
        the rank-sum test) when compared to all other algorithms of the table, with
        $p = 0.05$ or $p = 10^{-k}$ when the number $k$ following the star is larger
        than 1, with Bonferroni correction by the number of functions (55). A $\downarrow$ indicates the same tested against the best algorithm from BBOB 2016. Best results are printed in bold.
        \cocoversion}
\providecommand{\algsfolder}{GDE3_IBEA_MOEAD_N-III_N-III_NSGA-_SPEA2_et_al/}
\providecommand{\algorithmA}{GDE3}
\providecommand{\algorithmB}{IBEA}
\providecommand{\algorithmC}{MOEAD}
\providecommand{\algorithmD}{N-III-11}
\providecommand{\algorithmE}{N-III-111}
\providecommand{\algorithmF}{NSGA-II}
\providecommand{\algorithmG}{SPEA2}
